{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bb99fe-5d77-447f-af63-3cba88f826a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Directory setup\n",
    "dataset_dir = os.path.expanduser('~/Downloads/mvtec-loco-ad-DatasetNinja')\n",
    "\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "test_good_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "# Preprocessing\n",
    "img_height, img_width = 224, 224  # Resize dimensions, adjust as needed\n",
    "batch_size = 32\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Since we've changed train_datagen, recreate train_generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(dataset_dir, 'train', 'img'),\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input',  # Autoencoders don't have labels, input images are also targets\n",
    "    color_mode='rgb',\n",
    "    shuffle=True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(dataset_dir, 'test', 'img'),\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input',\n",
    "    color_mode='rgb',\n",
    "    shuffle=False)\n",
    "\n",
    "# print(os.listdir(train_dir))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd198f8d-67ee-4638-a1ba-5032bdc94fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_images(image_batch, num_images=8):\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(image_batch, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Fetch a batch of images from the train generator\n",
    "image_batch, _ = next(train_generator)  # Gets the next batch. Each batch has 'batch_size' images.\n",
    "\n",
    "# Display the first 'num_images' images from this batch\n",
    "display_images(image_batch[:8])  # Adjust the number to display as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0cd57f-a0a2-4e71-bd1a-5e0a0e3c6618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_images(image_batch, num_images=8):\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(image_batch, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Fetch a batch of images from the train generator\n",
    "image_batch, _ = next(test_generator)  # Gets the next batch. Each batch has 'batch_size' images.\n",
    "\n",
    "# Display the first 'num_images' images from this batch\n",
    "display_images(image_batch[:8])  # Adjust the number to display as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d3c81-7ad8-435c-9c17-8f64c57a74c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\n",
    "\n",
    "# Define the Sequential model\n",
    "autoencoder = Sequential([\n",
    "    Input(shape=(img_height, img_width, 3)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# You can now view the model summary\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a932846a-e5e2-4a19-af87-d1c20c110b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(train_generator, epochs=30, validation_data=train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43de033-6df9-47b1-b904-b58ac4a110c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab0cbc1-c6b6-4618-8cf1-9d20f873f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_anomaly_scores(model, generator, steps):\n",
    "    anomaly_scores = []\n",
    "    for _ in range(steps):\n",
    "        original_images, _ = next(generator)\n",
    "        reconstructed_images = model.predict_on_batch(original_images)\n",
    "        batch_scores = tf.reduce_mean(tf.abs(original_images - reconstructed_images), axis=(1, 2, 3))\n",
    "        anomaly_scores.extend(batch_scores.numpy())\n",
    "    return anomaly_scores\n",
    "\n",
    "# You'll need to specify the number of steps manually, as it depends on your dataset size and batch size.\n",
    "# Calculate steps as the total number of images divided by the batch size, and round up if necessary.\n",
    "steps = np.ceil(test_generator.samples / test_generator.batch_size)\n",
    "\n",
    "# Compute anomaly scores for the test set\n",
    "test_anomaly_scores = compute_anomaly_scores(autoencoder, test_generator, int(steps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4483c7-5220-4c8c-8e1c-96f8e635a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_anomalies_with_scores(model, generator, threshold, num_images):\n",
    "    plt.figure(figsize=(10, 2.5 * num_images))\n",
    "    for i in range(num_images):\n",
    "        original_images, _ = next(generator)\n",
    "        reconstructed_images = model.predict_on_batch(original_images)\n",
    "\n",
    "        # Compute anomaly scores for the current batch\n",
    "        anomaly_scores = np.mean(np.abs(original_images - reconstructed_images), axis=(1, 2, 3))\n",
    "\n",
    "        for j in range(len(original_images)):\n",
    "          # Display only the first `num_images` images\n",
    "          if i * len(original_images) + j >= num_images:\n",
    "              break\n",
    "\n",
    "          # Plot original image\n",
    "          ax = plt.subplot(num_images, 3, 3*j+1)\n",
    "          plt.imshow(original_images[j])\n",
    "          plt.title(f\"Original {i*len(original_images)+j+1}\")\n",
    "          plt.axis('off')\n",
    "\n",
    "          # Plot reconstructed image\n",
    "          ax = plt.subplot(num_images, 3, 3*j+2)\n",
    "          plt.imshow(reconstructed_images[j])\n",
    "          plt.title(f\"Reconstructed {i*len(original_images)+j+1}\")\n",
    "          plt.axis('off')\n",
    "\n",
    "          # Plot difference\n",
    "          difference = np.abs(original_images[j] - reconstructed_images[j])\n",
    "          ax = plt.subplot(num_images, 3, 3*j+3)\n",
    "          plt.imshow(difference)\n",
    "          anomaly_score = anomaly_scores[j]\n",
    "\n",
    "          if anomaly_score > threshold:\n",
    "            print(\"ANOMALY : \\n\", anomaly_score)\n",
    "            title = \"Anomaly\"\n",
    "          else:\n",
    "            title =  \"Normal\"\n",
    "            print(\"NORMAL : \\n\", anomaly_score)\n",
    "\n",
    "          plt.title(f\"{title} Score: {anomaly_score:.4f}\")\n",
    "          plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9757129-9a1e-4347-8672-57346363cf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.percentile(test_anomaly_scores, 0.065)\n",
    "print(sorted(test_anomaly_scores))\n",
    "print(threshold)\n",
    "for ele in test_anomaly_scores:\n",
    "  if ele > threshold:\n",
    "    print(\"ANOMALY :\", ele)\n",
    "  else:\n",
    "    print(\"NORMAL :\", ele)\n",
    "\n",
    "visualize_anomalies_with_scores(autoencoder, test_generator, threshold, num_images=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592f13d-32df-4e21-95a3-192f65174fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462c3d16-f67c-40aa-966a-3793a6f6aaef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8cb01-f921-40a1-aa7f-b883131e6c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
